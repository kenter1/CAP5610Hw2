{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, callbacks\n",
    "import tensorflow.keras as keras\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip,\n",
    "    Transpose, ShiftScaleRotate, Resize, RandomSizedCrop, RandomCrop, Rotate\n",
    ")\n",
    "\n",
    "def augment(aug, image):\n",
    "    image = aug(image=image)['image']\n",
    "    return image\n",
    "\n",
    "class CIFAR10AugmentationAndResize(tf.keras.utils.Sequence):\n",
    "    #Default size is 96 because it is one of the default train image size of mobilenetv2\n",
    "    def __init__(self, x_set, y_set, batch_size, \n",
    "                 augmentations = True,\n",
    "                 resize = False,\n",
    "                 height = 32, width = 32,\n",
    "                 pShiftScaleRotate = .2, pRandomSizedCrop = .2):\n",
    "        self.resize = resize\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.pShiftScaleRotate = pShiftScaleRotate\n",
    "        self.pRandomSizedCrop = pRandomSizedCrop      \n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        images = [imread(file_name) for file_name in batch_x]\n",
    "        \n",
    "        if(self.resize):\n",
    "            resize = Resize(height=self.height, width=self.width)\n",
    "        rotate = Rotate()\n",
    "        #shiftScaleRotate = ShiftScaleRotate(p=self.pShiftScaleRotate)\n",
    "        randomSizedCrop = RandomSizedCrop(min_max_height=(self.height - self.height * .25 ,self.height), height=self.height, width=self.width, p=self.pRandomSizedCrop)\n",
    "        horizontalFlip = HorizontalFlip()\n",
    "        \n",
    "        for i in range(len(images)):    \n",
    "            if(self.resize):\n",
    "                images[i] = augment(resize ,images[i])\n",
    "            \n",
    "            if(self.augmentations):\n",
    "                images[i] = augment(rotate ,images[i])\n",
    "                images[i] = augment(horizontalFlip ,images[i])\n",
    "                images[i] = augment(randomSizedCrop ,images[i])\n",
    "        \n",
    "        return np.array(images)/255, np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def architecture5():\n",
    "    model = tf.keras.Sequential([tf.keras.layers.Conv2D(32, (1, 1), input_shape=(32, 32, 3)),\n",
    "                               tf.keras.layers.BatchNormalization(),\n",
    "                               tf.keras.layers.Conv2D(16, 1,padding='same'),\n",
    "                               tf.keras.layers.BatchNormalization(),\n",
    "                               tf.keras.layers.Conv2D(32, (3, 3)),\n",
    "                               tf.keras.layers.BatchNormalization(),\n",
    "                               tf.keras.layers.MaxPooling2D(2,2),\n",
    "                               tf.keras.layers.ReLU(),\n",
    "                               tf.keras.layers.Conv2D(64, (1, 1)),\n",
    "                               tf.keras.layers.BatchNormalization(),\n",
    "                               tf.keras.layers.Conv2D(32, 1,padding='same'),\n",
    "                               tf.keras.layers.BatchNormalization(),\n",
    "                               tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "                               tf.keras.layers.BatchNormalization(),   \n",
    "                               tf.keras.layers.MaxPooling2D(2,2),\n",
    "                               tf.keras.layers.ReLU(),\n",
    "                               tf.keras.layers.Conv2D(128, (1, 1)),\n",
    "                               tf.keras.layers.BatchNormalization(),\n",
    "                               tf.keras.layers.Conv2D(64, 1,padding='same'),\n",
    "                               tf.keras.layers.BatchNormalization(),\n",
    "                               tf.keras.layers.Conv2D(128, (3, 3)),\n",
    "                               tf.keras.layers.BatchNormalization(),  \n",
    "                               tf.keras.layers.MaxPooling2D(2,2),\n",
    "                               tf.keras.layers.ReLU(),\n",
    "                               tf.keras.layers.Flatten(),\n",
    "                               tf.keras.layers.Dense(128, activation='relu'),\n",
    "                               tf.keras.layers.BatchNormalization(),\n",
    "                               tf.keras.layers.Dropout(.2),\n",
    "                               tf.keras.layers.Dense(64, activation='relu'),\n",
    "                               tf.keras.layers.BatchNormalization(),\n",
    "                               tf.keras.layers.Dropout(.2),\n",
    "                               tf.keras.layers.Dense(10, activation='softmax')\n",
    "                             ])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveModel(callbacks.Callback):\n",
    "    def __init__(self, filename):\n",
    "        super(SaveModel, self).__init__()\n",
    "        self.bestloss = 99999\n",
    "        self.filename = filename\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_loss, val_acc = logs['val_loss'], logs['val_accuracy']\n",
    "        \n",
    "        if(epoch % 50 == 0):\n",
    "            self.model.save(\"checkpoint{}_{}\".format(epoch // 50,self.filename), overwrite=True)\n",
    "        \n",
    "        if (self.bestloss > val_loss) :\n",
    "            self.bestloss = val_loss\n",
    "            print(\"\\nUpdating best model\")\n",
    "            self.model.save(\"{}\".format(self.filename), overwrite=True)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "location =  r\"E:\\Data\\CIFAR10\\Original\\Train\"\n",
    "files = sorted(os.listdir(location), key=lambda x : int(x[:-5]))\n",
    "train = [ r\"{}\\{}\".format(location,i) for i in files]\n",
    "\n",
    "location = r\"E:\\Data\\CIFAR10\\Original\"\n",
    "file = \"Train_Label.csv\"\n",
    "train_labels = pd.read_csv(r\"{}/{}\".format(location, file),index_col=0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.8299 - accuracy: 0.3479\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 1.8299 - accuracy: 0.3480 - val_loss: 1.5292 - val_accuracy: 0.4528\n",
      "Epoch 2/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.5533 - accuracy: 0.4450\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.5534 - accuracy: 0.4450 - val_loss: 1.3670 - val_accuracy: 0.5161\n",
      "Epoch 3/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.4556 - accuracy: 0.4832\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.4554 - accuracy: 0.4833 - val_loss: 1.1998 - val_accuracy: 0.5780\n",
      "Epoch 4/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.3904 - accuracy: 0.5106\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3905 - accuracy: 0.5107 - val_loss: 1.1686 - val_accuracy: 0.5845\n",
      "Epoch 5/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.3342 - accuracy: 0.5317\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3341 - accuracy: 0.5317 - val_loss: 1.0993 - val_accuracy: 0.6148\n",
      "Epoch 6/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.2974 - accuracy: 0.5466\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.2971 - accuracy: 0.5468 - val_loss: 1.0765 - val_accuracy: 0.6231\n",
      "Epoch 7/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.2591 - accuracy: 0.5587\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2592 - accuracy: 0.5586 - val_loss: 1.0180 - val_accuracy: 0.6442\n",
      "Epoch 8/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.2320 - accuracy: 0.5735\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2323 - accuracy: 0.5734 - val_loss: 0.9941 - val_accuracy: 0.6534\n",
      "Epoch 9/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.2079 - accuracy: 0.5826\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.2077 - accuracy: 0.5827 - val_loss: 0.9863 - val_accuracy: 0.6594\n",
      "Epoch 10/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.1882 - accuracy: 0.5870\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.1885 - accuracy: 0.5868 - val_loss: 0.9597 - val_accuracy: 0.6670\n",
      "Epoch 11/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.1565 - accuracy: 0.5984\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.1567 - accuracy: 0.5983 - val_loss: 0.9103 - val_accuracy: 0.6831\n",
      "Epoch 12/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.1444 - accuracy: 0.6037\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.1442 - accuracy: 0.6038 - val_loss: 0.8928 - val_accuracy: 0.6886\n",
      "Epoch 13/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.1359 - accuracy: 0.6059\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.1357 - accuracy: 0.6059 - val_loss: 0.8614 - val_accuracy: 0.7027\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.1179 - accuracy: 0.6133 - val_loss: 0.8837 - val_accuracy: 0.6939\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0956 - accuracy: 0.6233 - val_loss: 0.8703 - val_accuracy: 0.7000\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0848 - accuracy: 0.6263 - val_loss: 0.8707 - val_accuracy: 0.7040\n",
      "Epoch 17/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.0782 - accuracy: 0.6271\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0781 - accuracy: 0.6271 - val_loss: 0.8254 - val_accuracy: 0.7198\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0736 - accuracy: 0.6274 - val_loss: 0.8598 - val_accuracy: 0.7028\n",
      "Epoch 19/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.0535 - accuracy: 0.6373\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0535 - accuracy: 0.6373 - val_loss: 0.8082 - val_accuracy: 0.7174\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.0501 - accuracy: 0.6398 - val_loss: 0.8158 - val_accuracy: 0.7184\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0405 - accuracy: 0.6425 - val_loss: 0.8398 - val_accuracy: 0.7082\n",
      "Epoch 22/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.0321 - accuracy: 0.6457\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0319 - accuracy: 0.6457 - val_loss: 0.7758 - val_accuracy: 0.7301\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0331 - accuracy: 0.6431 - val_loss: 0.7948 - val_accuracy: 0.7197\n",
      "Epoch 24/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.0198 - accuracy: 0.6492\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0198 - accuracy: 0.6492 - val_loss: 0.7673 - val_accuracy: 0.7367\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0147 - accuracy: 0.6501 - val_loss: 0.7907 - val_accuracy: 0.7254\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.0109 - accuracy: 0.6520 - val_loss: 0.8146 - val_accuracy: 0.7180\n",
      "Epoch 27/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.9951 - accuracy: 0.6585\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9953 - accuracy: 0.6585 - val_loss: 0.7607 - val_accuracy: 0.7377\n",
      "Epoch 28/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.9897 - accuracy: 0.6600\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9896 - accuracy: 0.6601 - val_loss: 0.7514 - val_accuracy: 0.7390\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9884 - accuracy: 0.6588 - val_loss: 0.7718 - val_accuracy: 0.7338\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9833 - accuracy: 0.6618 - val_loss: 0.7620 - val_accuracy: 0.7410\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9753 - accuracy: 0.6653 - val_loss: 0.7650 - val_accuracy: 0.7343\n",
      "Epoch 32/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.9663 - accuracy: 0.6674\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9661 - accuracy: 0.6676 - val_loss: 0.7508 - val_accuracy: 0.7423\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9684 - accuracy: 0.6690 - val_loss: 0.7676 - val_accuracy: 0.7342\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9568 - accuracy: 0.6708 - val_loss: 0.7526 - val_accuracy: 0.7406\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9624 - accuracy: 0.6700 - val_loss: 0.7758 - val_accuracy: 0.7354\n",
      "Epoch 36/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.9544 - accuracy: 0.6729\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9543 - accuracy: 0.6730 - val_loss: 0.7012 - val_accuracy: 0.7608\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9463 - accuracy: 0.6736 - val_loss: 0.7382 - val_accuracy: 0.7430\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9470 - accuracy: 0.6749 - val_loss: 0.7405 - val_accuracy: 0.7440\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9437 - accuracy: 0.6758 - val_loss: 0.7237 - val_accuracy: 0.7491\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9445 - accuracy: 0.6757 - val_loss: 0.7373 - val_accuracy: 0.7484\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9279 - accuracy: 0.6808 - val_loss: 0.7179 - val_accuracy: 0.7482\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9280 - accuracy: 0.6815 - val_loss: 0.7316 - val_accuracy: 0.7456\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9296 - accuracy: 0.6828 - val_loss: 0.7085 - val_accuracy: 0.7549\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9278 - accuracy: 0.6819 - val_loss: 0.7224 - val_accuracy: 0.7524\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9223 - accuracy: 0.6828 - val_loss: 0.7195 - val_accuracy: 0.7479\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9135 - accuracy: 0.6864 - val_loss: 0.7204 - val_accuracy: 0.7509\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9110 - accuracy: 0.6866 - val_loss: 0.7023 - val_accuracy: 0.7620\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9121 - accuracy: 0.6848 - val_loss: 0.7259 - val_accuracy: 0.7489\n",
      "Epoch 49/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.9004 - accuracy: 0.6932\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9003 - accuracy: 0.6933 - val_loss: 0.6943 - val_accuracy: 0.7618\n",
      "Epoch 50/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.9039 - accuracy: 0.6918\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9038 - accuracy: 0.6918 - val_loss: 0.6936 - val_accuracy: 0.7600\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8970 - accuracy: 0.6942 - val_loss: 0.7092 - val_accuracy: 0.7529\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8963 - accuracy: 0.6910 - val_loss: 0.7317 - val_accuracy: 0.7482\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9023 - accuracy: 0.6922 - val_loss: 0.7030 - val_accuracy: 0.7602\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8895 - accuracy: 0.6970 - val_loss: 0.6957 - val_accuracy: 0.7618\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8901 - accuracy: 0.6974 - val_loss: 0.6963 - val_accuracy: 0.7608\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8812 - accuracy: 0.6992 - val_loss: 0.7192 - val_accuracy: 0.7518\n",
      "Epoch 57/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8825 - accuracy: 0.6974\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8825 - accuracy: 0.6974 - val_loss: 0.6837 - val_accuracy: 0.7657\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8815 - accuracy: 0.6977 - val_loss: 0.6898 - val_accuracy: 0.7602\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8812 - accuracy: 0.6992 - val_loss: 0.6948 - val_accuracy: 0.7591\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8791 - accuracy: 0.6990 - val_loss: 0.6942 - val_accuracy: 0.7618\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.8770 - accuracy: 0.6994 - val_loss: 0.6923 - val_accuracy: 0.7610\n",
      "Epoch 62/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8698 - accuracy: 0.7020\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8697 - accuracy: 0.7020 - val_loss: 0.6833 - val_accuracy: 0.7657\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8762 - accuracy: 0.7016 - val_loss: 0.6995 - val_accuracy: 0.7591\n",
      "Epoch 64/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8697 - accuracy: 0.7033\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8695 - accuracy: 0.7034 - val_loss: 0.6777 - val_accuracy: 0.7622\n",
      "Epoch 65/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.8685 - accuracy: 0.7021\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8688 - accuracy: 0.7021 - val_loss: 0.6770 - val_accuracy: 0.7694\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8675 - accuracy: 0.7017 - val_loss: 0.6776 - val_accuracy: 0.7649\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8675 - accuracy: 0.7021 - val_loss: 0.6778 - val_accuracy: 0.7700\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8574 - accuracy: 0.7042 - val_loss: 0.6913 - val_accuracy: 0.7586\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8581 - accuracy: 0.7042 - val_loss: 0.6820 - val_accuracy: 0.7672\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8518 - accuracy: 0.7082 - val_loss: 0.7006 - val_accuracy: 0.7575\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8555 - accuracy: 0.7075 - val_loss: 0.6936 - val_accuracy: 0.7576\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8554 - accuracy: 0.7044 - val_loss: 0.6877 - val_accuracy: 0.7653\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8505 - accuracy: 0.7107 - val_loss: 0.6855 - val_accuracy: 0.7656\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8515 - accuracy: 0.7086 - val_loss: 0.6787 - val_accuracy: 0.7677\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8502 - accuracy: 0.7085 - val_loss: 0.6970 - val_accuracy: 0.7563\n",
      "Epoch 76/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8475 - accuracy: 0.7107\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8474 - accuracy: 0.7107 - val_loss: 0.6630 - val_accuracy: 0.7724\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8447 - accuracy: 0.7099 - val_loss: 0.6760 - val_accuracy: 0.7683\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8475 - accuracy: 0.7094 - val_loss: 0.6715 - val_accuracy: 0.7690\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8425 - accuracy: 0.7117 - val_loss: 0.6928 - val_accuracy: 0.7609\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8401 - accuracy: 0.7135 - val_loss: 0.6755 - val_accuracy: 0.7644\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8435 - accuracy: 0.7135 - val_loss: 0.6652 - val_accuracy: 0.7735\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8445 - accuracy: 0.7115 - val_loss: 0.6916 - val_accuracy: 0.7629\n",
      "Epoch 83/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8393 - accuracy: 0.7136\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8391 - accuracy: 0.7137 - val_loss: 0.6588 - val_accuracy: 0.7738\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8327 - accuracy: 0.7145 - val_loss: 0.6783 - val_accuracy: 0.7685\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8311 - accuracy: 0.7146 - val_loss: 0.6779 - val_accuracy: 0.7683\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8386 - accuracy: 0.7115 - val_loss: 0.6731 - val_accuracy: 0.7704\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8360 - accuracy: 0.7135 - val_loss: 0.6734 - val_accuracy: 0.7677\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8330 - accuracy: 0.7150 - val_loss: 0.6678 - val_accuracy: 0.7696\n",
      "Epoch 89/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8257 - accuracy: 0.7171 - val_loss: 0.6670 - val_accuracy: 0.7718\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8227 - accuracy: 0.7195 - val_loss: 0.6917 - val_accuracy: 0.7656\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8279 - accuracy: 0.7164 - val_loss: 0.6612 - val_accuracy: 0.7720\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8247 - accuracy: 0.7185 - val_loss: 0.6731 - val_accuracy: 0.7702\n",
      "Epoch 93/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8184 - accuracy: 0.7175\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8184 - accuracy: 0.7175 - val_loss: 0.6526 - val_accuracy: 0.7767\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8184 - accuracy: 0.7194 - val_loss: 0.6714 - val_accuracy: 0.7706\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8200 - accuracy: 0.7194 - val_loss: 0.6664 - val_accuracy: 0.7713\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8138 - accuracy: 0.7222 - val_loss: 0.6587 - val_accuracy: 0.7746\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8204 - accuracy: 0.7188 - val_loss: 0.6700 - val_accuracy: 0.7686\n",
      "Epoch 98/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8140 - accuracy: 0.7182 - val_loss: 0.6641 - val_accuracy: 0.7729\n",
      "Epoch 99/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8155 - accuracy: 0.7196 - val_loss: 0.6636 - val_accuracy: 0.7711\n",
      "Epoch 100/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8188 - accuracy: 0.7211\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8189 - accuracy: 0.7209 - val_loss: 0.6449 - val_accuracy: 0.7777\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 36s 29ms/step - loss: 1.8354 - accuracy: 0.3421 - val_loss: 1.4934 - val_accuracy: 0.4692\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.5651 - accuracy: 0.4404 - val_loss: 1.2618 - val_accuracy: 0.5446\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.4558 - accuracy: 0.4840 - val_loss: 1.1841 - val_accuracy: 0.5815\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3841 - accuracy: 0.5105 - val_loss: 1.1589 - val_accuracy: 0.5818\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3253 - accuracy: 0.5342 - val_loss: 1.0359 - val_accuracy: 0.6375\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.2858 - accuracy: 0.5498 - val_loss: 1.0180 - val_accuracy: 0.6446\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.2538 - accuracy: 0.5622 - val_loss: 0.9595 - val_accuracy: 0.6643\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.2182 - accuracy: 0.5754 - val_loss: 1.0262 - val_accuracy: 0.6402\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.1870 - accuracy: 0.5872 - val_loss: 0.9296 - val_accuracy: 0.6735\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.1687 - accuracy: 0.5982 - val_loss: 0.9483 - val_accuracy: 0.6713\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.1520 - accuracy: 0.5995 - val_loss: 0.9217 - val_accuracy: 0.6794\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.1366 - accuracy: 0.6078 - val_loss: 0.8993 - val_accuracy: 0.6857\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.1113 - accuracy: 0.6172 - val_loss: 0.8719 - val_accuracy: 0.6944\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.1042 - accuracy: 0.6189 - val_loss: 0.8534 - val_accuracy: 0.7077\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.0843 - accuracy: 0.6240 - val_loss: 0.8347 - val_accuracy: 0.7075\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.0814 - accuracy: 0.6252 - val_loss: 0.7974 - val_accuracy: 0.7194\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.0793 - accuracy: 0.6266 - val_loss: 0.8114 - val_accuracy: 0.7173\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.0559 - accuracy: 0.6359 - val_loss: 0.8099 - val_accuracy: 0.7205\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.0475 - accuracy: 0.6391 - val_loss: 0.8212 - val_accuracy: 0.7162\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.0398 - accuracy: 0.6448 - val_loss: 0.7930 - val_accuracy: 0.7242\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.0300 - accuracy: 0.6465 - val_loss: 0.7958 - val_accuracy: 0.7277\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.0229 - accuracy: 0.6473 - val_loss: 0.7805 - val_accuracy: 0.7315\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.0193 - accuracy: 0.6514 - val_loss: 0.8013 - val_accuracy: 0.7176\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.0130 - accuracy: 0.6510 - val_loss: 0.8484 - val_accuracy: 0.7035\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.0029 - accuracy: 0.6562 - val_loss: 0.7930 - val_accuracy: 0.7249\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9973 - accuracy: 0.6575 - val_loss: 0.7426 - val_accuracy: 0.7393\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9830 - accuracy: 0.6623 - val_loss: 0.7434 - val_accuracy: 0.7401\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9796 - accuracy: 0.6639 - val_loss: 0.7525 - val_accuracy: 0.7412\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9768 - accuracy: 0.6653 - val_loss: 0.7479 - val_accuracy: 0.7413\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9747 - accuracy: 0.6667 - val_loss: 0.7411 - val_accuracy: 0.7400\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9677 - accuracy: 0.6654 - val_loss: 0.7546 - val_accuracy: 0.7373\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9657 - accuracy: 0.6684 - val_loss: 0.7232 - val_accuracy: 0.7463\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9596 - accuracy: 0.6694 - val_loss: 0.7306 - val_accuracy: 0.7481\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9528 - accuracy: 0.6731 - val_loss: 0.7274 - val_accuracy: 0.7496\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9471 - accuracy: 0.6740 - val_loss: 0.7243 - val_accuracy: 0.7489\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9443 - accuracy: 0.6753 - val_loss: 0.7286 - val_accuracy: 0.7479\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9305 - accuracy: 0.6815 - val_loss: 0.7166 - val_accuracy: 0.7540\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.9311 - accuracy: 0.6824 - val_loss: 0.7158 - val_accuracy: 0.7553\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.9362 - accuracy: 0.6780 - val_loss: 0.7460 - val_accuracy: 0.7405\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.9296 - accuracy: 0.6802 - val_loss: 0.7372 - val_accuracy: 0.7454\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.9243 - accuracy: 0.6844 - val_loss: 0.7096 - val_accuracy: 0.7525\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.9188 - accuracy: 0.6855 - val_loss: 0.7347 - val_accuracy: 0.7443\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.9198 - accuracy: 0.6862 - val_loss: 0.7117 - val_accuracy: 0.7526\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.9103 - accuracy: 0.6887 - val_loss: 0.7067 - val_accuracy: 0.7538\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.9120 - accuracy: 0.6903 - val_loss: 0.7211 - val_accuracy: 0.7506\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.9078 - accuracy: 0.6887 - val_loss: 0.6938 - val_accuracy: 0.7620\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.9062 - accuracy: 0.6862 - val_loss: 0.7197 - val_accuracy: 0.7524\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8969 - accuracy: 0.6934 - val_loss: 0.6948 - val_accuracy: 0.7587\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8979 - accuracy: 0.6930 - val_loss: 0.7042 - val_accuracy: 0.7546\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.9018 - accuracy: 0.6909 - val_loss: 0.6779 - val_accuracy: 0.7643\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.8868 - accuracy: 0.6981 - val_loss: 0.7038 - val_accuracy: 0.7552\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.8860 - accuracy: 0.6981 - val_loss: 0.7028 - val_accuracy: 0.7604\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.8898 - accuracy: 0.6943 - val_loss: 0.6911 - val_accuracy: 0.7563\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8955 - accuracy: 0.6946 - val_loss: 0.6775 - val_accuracy: 0.7678\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.8832 - accuracy: 0.6973 - val_loss: 0.6781 - val_accuracy: 0.7656\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8793 - accuracy: 0.6995 - val_loss: 0.7063 - val_accuracy: 0.7547\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.8817 - accuracy: 0.6961 - val_loss: 0.6793 - val_accuracy: 0.7681\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8707 - accuracy: 0.7020 - val_loss: 0.6840 - val_accuracy: 0.7677\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8801 - accuracy: 0.6978 - val_loss: 0.6893 - val_accuracy: 0.7638\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8722 - accuracy: 0.7035 - val_loss: 0.7128 - val_accuracy: 0.7582\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8673 - accuracy: 0.7015 - val_loss: 0.7095 - val_accuracy: 0.7538\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8652 - accuracy: 0.7060 - val_loss: 0.7196 - val_accuracy: 0.7516\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8706 - accuracy: 0.6997 - val_loss: 0.6889 - val_accuracy: 0.7644\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8619 - accuracy: 0.7060 - val_loss: 0.6746 - val_accuracy: 0.7679\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8588 - accuracy: 0.7076 - val_loss: 0.6854 - val_accuracy: 0.7673\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8584 - accuracy: 0.7055 - val_loss: 0.6845 - val_accuracy: 0.7659\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8583 - accuracy: 0.7048 - val_loss: 0.6747 - val_accuracy: 0.7653\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8552 - accuracy: 0.7092 - val_loss: 0.7041 - val_accuracy: 0.7621\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.8535 - accuracy: 0.7072 - val_loss: 0.6732 - val_accuracy: 0.7691\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8571 - accuracy: 0.7072 - val_loss: 0.6793 - val_accuracy: 0.7625\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.8502 - accuracy: 0.7107 - val_loss: 0.6672 - val_accuracy: 0.7736\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8449 - accuracy: 0.7102 - val_loss: 0.6762 - val_accuracy: 0.7694\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8487 - accuracy: 0.7085 - val_loss: 0.6727 - val_accuracy: 0.7676\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.8484 - accuracy: 0.7073 - val_loss: 0.6820 - val_accuracy: 0.7700\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8410 - accuracy: 0.7137 - val_loss: 0.6590 - val_accuracy: 0.7720\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8417 - accuracy: 0.7121 - val_loss: 0.6590 - val_accuracy: 0.7721\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8323 - accuracy: 0.7161 - val_loss: 0.6667 - val_accuracy: 0.7693\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8364 - accuracy: 0.7129 - val_loss: 0.6772 - val_accuracy: 0.7682\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8345 - accuracy: 0.7153 - val_loss: 0.6728 - val_accuracy: 0.7706\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8266 - accuracy: 0.7157 - val_loss: 0.6705 - val_accuracy: 0.7698\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8393 - accuracy: 0.7127 - val_loss: 0.7017 - val_accuracy: 0.7570\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8354 - accuracy: 0.7119 - val_loss: 0.6743 - val_accuracy: 0.7683\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8318 - accuracy: 0.7146 - val_loss: 0.6618 - val_accuracy: 0.7732\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8304 - accuracy: 0.7171 - val_loss: 0.6849 - val_accuracy: 0.7690\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.8264 - accuracy: 0.7162 - val_loss: 0.6615 - val_accuracy: 0.7755\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8188 - accuracy: 0.7212 - val_loss: 0.6513 - val_accuracy: 0.7765\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8177 - accuracy: 0.7216 - val_loss: 0.6710 - val_accuracy: 0.7718\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8236 - accuracy: 0.7181 - val_loss: 0.6624 - val_accuracy: 0.7770\n",
      "Epoch 89/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8216 - accuracy: 0.7197\n",
      "Updating best model\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8214 - accuracy: 0.7198 - val_loss: 0.6383 - val_accuracy: 0.7823\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8131 - accuracy: 0.7215 - val_loss: 0.6665 - val_accuracy: 0.7766\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8211 - accuracy: 0.7191 - val_loss: 0.6645 - val_accuracy: 0.7726\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8212 - accuracy: 0.7182 - val_loss: 0.6537 - val_accuracy: 0.7776\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8105 - accuracy: 0.7222 - val_loss: 0.6801 - val_accuracy: 0.7672\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8145 - accuracy: 0.7232 - val_loss: 0.6575 - val_accuracy: 0.7780\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8132 - accuracy: 0.7218 - val_loss: 0.6603 - val_accuracy: 0.7754\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8064 - accuracy: 0.7247 - val_loss: 0.6608 - val_accuracy: 0.7764\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8063 - accuracy: 0.7244 - val_loss: 0.6527 - val_accuracy: 0.7779\n",
      "Epoch 98/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8062 - accuracy: 0.7246 - val_loss: 0.6618 - val_accuracy: 0.7742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8066 - accuracy: 0.7234 - val_loss: 0.6452 - val_accuracy: 0.7802\n",
      "Epoch 100/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8034 - accuracy: 0.7256 - val_loss: 0.6789 - val_accuracy: 0.7672\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 1.8316 - accuracy: 0.3464 - val_loss: 1.4308 - val_accuracy: 0.4808\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.5594 - accuracy: 0.4405 - val_loss: 1.3077 - val_accuracy: 0.5285\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.4622 - accuracy: 0.4805 - val_loss: 1.1927 - val_accuracy: 0.5721\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3934 - accuracy: 0.5055 - val_loss: 1.2091 - val_accuracy: 0.5720\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3457 - accuracy: 0.5256 - val_loss: 1.1586 - val_accuracy: 0.5963\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.3024 - accuracy: 0.5436 - val_loss: 1.0177 - val_accuracy: 0.6441\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.2616 - accuracy: 0.5612 - val_loss: 1.0267 - val_accuracy: 0.6375\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2321 - accuracy: 0.5721 - val_loss: 1.0466 - val_accuracy: 0.6373\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2072 - accuracy: 0.5799 - val_loss: 0.9876 - val_accuracy: 0.6545\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.1878 - accuracy: 0.5859 - val_loss: 0.9727 - val_accuracy: 0.6560\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.1658 - accuracy: 0.5965 - val_loss: 0.9101 - val_accuracy: 0.6823\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.1473 - accuracy: 0.6036 - val_loss: 0.9197 - val_accuracy: 0.6830\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.1295 - accuracy: 0.6076 - val_loss: 0.8946 - val_accuracy: 0.6831\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.1098 - accuracy: 0.6192 - val_loss: 0.8588 - val_accuracy: 0.7020\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.1043 - accuracy: 0.6181 - val_loss: 0.8779 - val_accuracy: 0.6941\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.0927 - accuracy: 0.6226 - val_loss: 0.9013 - val_accuracy: 0.6903\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.0810 - accuracy: 0.6305 - val_loss: 0.8580 - val_accuracy: 0.7065\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.0710 - accuracy: 0.6335 - val_loss: 0.8311 - val_accuracy: 0.7113\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.0657 - accuracy: 0.6355 - val_loss: 0.8752 - val_accuracy: 0.7022\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.0570 - accuracy: 0.6378 - val_loss: 0.8297 - val_accuracy: 0.7153\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.0455 - accuracy: 0.6405 - val_loss: 0.8286 - val_accuracy: 0.7178\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.0394 - accuracy: 0.6430 - val_loss: 0.8194 - val_accuracy: 0.7180\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.0314 - accuracy: 0.6450 - val_loss: 0.8037 - val_accuracy: 0.7226\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.0181 - accuracy: 0.6478 - val_loss: 0.8127 - val_accuracy: 0.7164\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 1.0162 - accuracy: 0.6512 - val_loss: 0.8219 - val_accuracy: 0.7207\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.0093 - accuracy: 0.6554 - val_loss: 0.7857 - val_accuracy: 0.7265\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9951 - accuracy: 0.6593 - val_loss: 0.7936 - val_accuracy: 0.7253\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9941 - accuracy: 0.6579 - val_loss: 0.7772 - val_accuracy: 0.7323\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9947 - accuracy: 0.6594 - val_loss: 0.8169 - val_accuracy: 0.7223\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9849 - accuracy: 0.6621 - val_loss: 0.7655 - val_accuracy: 0.7379\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.9799 - accuracy: 0.6646 - val_loss: 0.7668 - val_accuracy: 0.7372\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9858 - accuracy: 0.6634 - val_loss: 0.7803 - val_accuracy: 0.7311\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.9723 - accuracy: 0.6671 - val_loss: 0.7373 - val_accuracy: 0.7486\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.9669 - accuracy: 0.6682 - val_loss: 0.7663 - val_accuracy: 0.7350\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.9608 - accuracy: 0.6700 - val_loss: 0.7776 - val_accuracy: 0.7305\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.9583 - accuracy: 0.6726 - val_loss: 0.7774 - val_accuracy: 0.7341\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.9469 - accuracy: 0.6759 - val_loss: 0.7373 - val_accuracy: 0.7445\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.9545 - accuracy: 0.6714 - val_loss: 0.7436 - val_accuracy: 0.7465\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.9455 - accuracy: 0.6733 - val_loss: 0.7556 - val_accuracy: 0.7396\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.9397 - accuracy: 0.6788 - val_loss: 0.7340 - val_accuracy: 0.7494\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.9380 - accuracy: 0.6795 - val_loss: 0.7627 - val_accuracy: 0.7376\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9380 - accuracy: 0.6789 - val_loss: 0.7261 - val_accuracy: 0.7533\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9304 - accuracy: 0.6813 - val_loss: 0.7789 - val_accuracy: 0.7335\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9344 - accuracy: 0.6791 - val_loss: 0.7476 - val_accuracy: 0.7429\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9222 - accuracy: 0.6848 - val_loss: 0.7213 - val_accuracy: 0.7511\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9205 - accuracy: 0.6867 - val_loss: 0.7400 - val_accuracy: 0.7465\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9206 - accuracy: 0.6846 - val_loss: 0.7654 - val_accuracy: 0.7400\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.9130 - accuracy: 0.6892 - val_loss: 0.7192 - val_accuracy: 0.7534\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9102 - accuracy: 0.6878 - val_loss: 0.7393 - val_accuracy: 0.7454\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9074 - accuracy: 0.6915 - val_loss: 0.7266 - val_accuracy: 0.7552\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9040 - accuracy: 0.6913 - val_loss: 0.7140 - val_accuracy: 0.7543\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9040 - accuracy: 0.6895 - val_loss: 0.7147 - val_accuracy: 0.7540\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8954 - accuracy: 0.6908 - val_loss: 0.7146 - val_accuracy: 0.7573\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8953 - accuracy: 0.6928 - val_loss: 0.7393 - val_accuracy: 0.7443\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8906 - accuracy: 0.6964 - val_loss: 0.7368 - val_accuracy: 0.7489\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8950 - accuracy: 0.6913 - val_loss: 0.7158 - val_accuracy: 0.7564\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8944 - accuracy: 0.6938 - val_loss: 0.7133 - val_accuracy: 0.7529\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8891 - accuracy: 0.6944 - val_loss: 0.6984 - val_accuracy: 0.7610\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8866 - accuracy: 0.6956 - val_loss: 0.6964 - val_accuracy: 0.7637\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8784 - accuracy: 0.6988 - val_loss: 0.7199 - val_accuracy: 0.7546\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8770 - accuracy: 0.7010 - val_loss: 0.7262 - val_accuracy: 0.7511\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8790 - accuracy: 0.6993 - val_loss: 0.7119 - val_accuracy: 0.7555\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.8795 - accuracy: 0.6971 - val_loss: 0.6984 - val_accuracy: 0.7616\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8718 - accuracy: 0.7023 - val_loss: 0.6967 - val_accuracy: 0.7626\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8759 - accuracy: 0.7016 - val_loss: 0.6869 - val_accuracy: 0.7625\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8670 - accuracy: 0.7053 - val_loss: 0.7006 - val_accuracy: 0.7609\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8651 - accuracy: 0.7065 - val_loss: 0.7002 - val_accuracy: 0.7625\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8552 - accuracy: 0.7082 - val_loss: 0.6902 - val_accuracy: 0.7654\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8631 - accuracy: 0.7041 - val_loss: 0.6855 - val_accuracy: 0.7654\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8607 - accuracy: 0.7053 - val_loss: 0.6915 - val_accuracy: 0.7663\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.8600 - accuracy: 0.7057 - val_loss: 0.7105 - val_accuracy: 0.7577\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8590 - accuracy: 0.7045 - val_loss: 0.6691 - val_accuracy: 0.7685\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8510 - accuracy: 0.7089 - val_loss: 0.6896 - val_accuracy: 0.7637\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8529 - accuracy: 0.7084 - val_loss: 0.6896 - val_accuracy: 0.7630\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8535 - accuracy: 0.7097 - val_loss: 0.7052 - val_accuracy: 0.7581\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8457 - accuracy: 0.7146 - val_loss: 0.7008 - val_accuracy: 0.7587\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8455 - accuracy: 0.7128 - val_loss: 0.6795 - val_accuracy: 0.7677\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8506 - accuracy: 0.7095 - val_loss: 0.6733 - val_accuracy: 0.7682\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8441 - accuracy: 0.7123 - val_loss: 0.6962 - val_accuracy: 0.7654\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8482 - accuracy: 0.7099 - val_loss: 0.7026 - val_accuracy: 0.7581\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 0.8431 - accuracy: 0.7098 - val_loss: 0.6878 - val_accuracy: 0.7660\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 0.8325 - accuracy: 0.7139 - val_loss: 0.6808 - val_accuracy: 0.7723\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8345 - accuracy: 0.7142 - val_loss: 0.6846 - val_accuracy: 0.7687\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8369 - accuracy: 0.7144 - val_loss: 0.6945 - val_accuracy: 0.7631\n",
      "Epoch 85/100\n",
      " 184/1250 [===>..........................] - ETA: 20s - loss: 0.8143 - accuracy: 0.7232"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ac9403139906>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     history.append(model.fit_generator(train_seq, \n\u001b[0;32m     23\u001b[0m                                        \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_seq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                                        epochs=100, shuffle=True, callbacks=callback))\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1515\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1257\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1259\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3217\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[0;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m--> 558\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args)\u001b[0m\n\u001b[0;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[0;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[1;32m--> 415\u001b[1;33m             ctx=ctx)\n\u001b[0m\u001b[0;32m    416\u001b[0m       \u001b[1;31m# Replace empty list with None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "callback = [SaveModel(\"architecture5.h5\")]\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for train_, valid in kf.split(train, train_labels):\n",
    "    train_x, valid_x = np.array(train)[train_],  np.array(train)[valid]\n",
    "    train_y, valid_y = np.array(train_labels)[train_],  np.array(train_labels)[valid]\n",
    "    \n",
    "    train_seq = CIFAR10AugmentationAndResize(train_x, train_y, batch_size)\n",
    "    validation_seq = CIFAR10AugmentationAndResize(valid_x, valid_y, batch_size, augmentations=False)\n",
    "    \n",
    "    model = architecture5()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    history.append(model.fit_generator(train_seq, \n",
    "                                       validation_data=validation_seq, \n",
    "                                       epochs=100, shuffle=True, callbacks=callback))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_44 (B (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 32, 32, 16)        528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_45 (B (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 30, 30, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_46 (B (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 15, 15, 64)        2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_47 (B (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 15, 15, 32)        2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_48 (B (None, 15, 15, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_49 (B (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 6, 6, 128)         8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_50 (B (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 6, 6, 64)          8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_51 (B (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_52 (B (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_53 (B (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_54 (B (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 195,994\n",
      "Trainable params: 194,490\n",
      "Non-trainable params: 1,504\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6522712220970434, 0.7781]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "location =  r\"E:\\Data\\CIFAR10\\Original\\Test\"\n",
    "files = sorted(os.listdir(location), key=lambda x : int(x[:-5]))\n",
    "test = [ r\"{}\\{}\".format(location,i) for i in files]\n",
    "\n",
    "location = r\"E:\\Data\\CIFAR10\\Original\"\n",
    "file = \"Test_Label.csv\"\n",
    "test_labels = pd.read_csv(r\"{}/{}\".format(location, file),index_col=0).values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "batch_size = 32\n",
    "test_seq = CIFAR10AugmentationAndResize(test, test_labels, batch_size,height=96,augmentations=False)\n",
    "\n",
    "model = architecture5()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.load_weights(\"architecture5.h5\")\n",
    "\n",
    "model.evaluate_generator(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

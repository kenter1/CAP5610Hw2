{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from:\n",
    "\n",
    "https://github.com/msurtsukov/neural-ode\n",
    "\n",
    "https://github.com/rtqichen/torchdiffeq\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.color_palette(\"bright\")\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn  import functional as F \n",
    "from torch.autograd import Variable\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(dim):\n",
    "    return nn.BatchNorm2d(dim)\n",
    "\n",
    "def conv3x3(in_feats, out_feats, stride=1):\n",
    "    return nn.Conv2d(in_feats, out_feats, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "def add_time(in_tensor, t):\n",
    "    bs, c, w, h = in_tensor.shape\n",
    "    return torch.cat((in_tensor, t.expand(bs, 1, w, h)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEF(nn.Module):\n",
    "    def forward_with_grad(self, z, t, grad_outputs):\n",
    "        \"\"\"Compute f and a df/dz, a df/dp, a df/dt\"\"\"\n",
    "        batch_size = z.shape[0]\n",
    "\n",
    "        out = self.forward(z, t)\n",
    "\n",
    "        a = grad_outputs\n",
    "        adfdz, adfdt, *adfdp = torch.autograd.grad(\n",
    "            (out,), (z, t) + tuple(self.parameters()), grad_outputs=(a),\n",
    "            allow_unused=True, retain_graph=True\n",
    "        )\n",
    "        # grad method automatically sums gradients for batch items, we have to expand them back \n",
    "        if adfdp is not None:\n",
    "            adfdp = torch.cat([p_grad.flatten() for p_grad in adfdp]).unsqueeze(0)\n",
    "            adfdp = adfdp.expand(batch_size, -1) / batch_size\n",
    "        if adfdt is not None:\n",
    "            adfdt = adfdt.expand(batch_size, 1) / batch_size\n",
    "        return out, adfdz, adfdt, adfdp\n",
    "\n",
    "    def flatten_parameters(self):\n",
    "        p_shapes = []\n",
    "        flat_parameters = []\n",
    "        for p in self.parameters():\n",
    "            p_shapes.append(p.size())\n",
    "            flat_parameters.append(p.flatten())\n",
    "        return torch.cat(flat_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvODEF(ODEF):\n",
    "    def __init__(self, dim):\n",
    "        super(ConvODEF, self).__init__()\n",
    "        self.conv1 = conv3x3(dim + 1, dim)\n",
    "        self.norm1 = norm(dim)\n",
    "        self.conv2 = conv3x3(dim + 1, dim)\n",
    "        self.norm2 = norm(dim)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        xt = add_time(x, t)\n",
    "        h = self.norm1(torch.relu(self.conv1(xt)))\n",
    "        ht = add_time(h, t)\n",
    "        dxdt = self.norm2(torch.relu(self.conv2(ht)))\n",
    "        return dxdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, ode):\n",
    "        super(Net, self).__init__()\n",
    "        self.downsampling = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
    "            norm(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 4, 2, 1),\n",
    "            norm(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 4, 2, 1),\n",
    "        )\n",
    "        self.feature = ode\n",
    "        self.norm = norm(64)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsampling(x)\n",
    "        x = self.feature(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.avg_pool(x)\n",
    "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
    "        x = x.view(-1, shape)\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousNeuralMNISTClassifier(nn.Module):\n",
    "    def __init__(self, ode):\n",
    "        super(ContinuousNeuralMNISTClassifier, self).__init__()\n",
    "        self.downsampling = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, 1),\n",
    "            norm(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 4, 2, 1),\n",
    "            norm(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 4, 2, 1),\n",
    "        )\n",
    "        self.feature = ode\n",
    "        self.norm = norm(64)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsampling(x)\n",
    "        x = self.feature(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.avg_pool(x)\n",
    "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
    "        x = x.view(-1, shape)\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralODE(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super(NeuralODE, self).__init__()\n",
    "        assert isinstance(func, ODEF)\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, z0, t=Tensor([0., 1.]), return_whole_sequence=False):\n",
    "        t = t.to(z0)\n",
    "        z = ODEAdjoint.apply(z0, t, self.func.flatten_parameters(), self.func)\n",
    "        if return_whole_sequence:\n",
    "            return z\n",
    "        else:\n",
    "            return z[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEAdjoint(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, z0, t, flat_parameters, func):\n",
    "        assert isinstance(func, ODEF)\n",
    "        bs, *z_shape = z0.size()\n",
    "        time_len = t.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = torch.zeros(time_len, bs, *z_shape).to(z0)\n",
    "            z[0] = z0\n",
    "            for i_t in range(time_len - 1):\n",
    "                z0 = ode_solve(z0, t[i_t], t[i_t+1], func)\n",
    "                z[i_t+1] = z0\n",
    "\n",
    "        ctx.func = func\n",
    "        ctx.save_for_backward(t, z.clone(), flat_parameters)\n",
    "        return z\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dLdz):\n",
    "        \"\"\"\n",
    "        dLdz shape: time_len, batch_size, *z_shape\n",
    "        \"\"\"\n",
    "        func = ctx.func\n",
    "        t, z, flat_parameters = ctx.saved_tensors\n",
    "        time_len, bs, *z_shape = z.size()\n",
    "        n_dim = np.prod(z_shape)\n",
    "        n_params = flat_parameters.size(0)\n",
    "\n",
    "        # Dynamics of augmented system to be calculated backwards in time\n",
    "        def augmented_dynamics(aug_z_i, t_i):\n",
    "            \"\"\"\n",
    "            tensors here are temporal slices\n",
    "            t_i - is tensor with size: bs, 1\n",
    "            aug_z_i - is tensor with size: bs, n_dim*2 + n_params + 1\n",
    "            \"\"\"\n",
    "            z_i, a = aug_z_i[:, :n_dim], aug_z_i[:, n_dim:2*n_dim]  # ignore parameters and time\n",
    "\n",
    "            # Unflatten z and a\n",
    "            z_i = z_i.view(bs, *z_shape)\n",
    "            a = a.view(bs, *z_shape)\n",
    "            with torch.set_grad_enabled(True):\n",
    "                t_i = t_i.detach().requires_grad_(True)\n",
    "                z_i = z_i.detach().requires_grad_(True)\n",
    "                func_eval, adfdz, adfdt, adfdp = func.forward_with_grad(z_i, t_i, grad_outputs=a)  # bs, *z_shape\n",
    "                adfdz = adfdz.to(z_i) if adfdz is not None else torch.zeros(bs, *z_shape).to(z_i)\n",
    "                adfdp = adfdp.to(z_i) if adfdp is not None else torch.zeros(bs, n_params).to(z_i)\n",
    "                adfdt = adfdt.to(z_i) if adfdt is not None else torch.zeros(bs, 1).to(z_i)\n",
    "\n",
    "            # Flatten f and adfdz\n",
    "            func_eval = func_eval.view(bs, n_dim)\n",
    "            adfdz = adfdz.view(bs, n_dim) \n",
    "            return torch.cat((func_eval, -adfdz, -adfdp, -adfdt), dim=1)\n",
    "\n",
    "        dLdz = dLdz.view(time_len, bs, n_dim)  # flatten dLdz for convenience\n",
    "        with torch.no_grad():\n",
    "            ## Create placeholders for output gradients\n",
    "            # Prev computed backwards adjoints to be adjusted by direct gradients\n",
    "            adj_z = torch.zeros(bs, n_dim).to(dLdz)\n",
    "            adj_p = torch.zeros(bs, n_params).to(dLdz)\n",
    "            # In contrast to z and p we need to return gradients for all times\n",
    "            adj_t = torch.zeros(time_len, bs, 1).to(dLdz)\n",
    "\n",
    "            for i_t in range(time_len-1, 0, -1):\n",
    "                z_i = z[i_t]\n",
    "                t_i = t[i_t]\n",
    "                f_i = func(z_i, t_i).view(bs, n_dim)\n",
    "\n",
    "                # Compute direct gradients\n",
    "                dLdz_i = dLdz[i_t]\n",
    "                dLdt_i = torch.bmm(torch.transpose(dLdz_i.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0]\n",
    "\n",
    "                # Adjusting adjoints with direct gradients\n",
    "                adj_z += dLdz_i\n",
    "                adj_t[i_t] = adj_t[i_t] - dLdt_i\n",
    "\n",
    "                # Pack augmented variable\n",
    "                aug_z = torch.cat((z_i.view(bs, n_dim), adj_z, torch.zeros(bs, n_params).to(z), adj_t[i_t]), dim=-1)\n",
    "\n",
    "                # Solve augmented system backwards\n",
    "                aug_ans = ode_solve(aug_z, t_i, t[i_t-1], augmented_dynamics)\n",
    "\n",
    "                # Unpack solved backwards augmented system\n",
    "                adj_z[:] = aug_ans[:, n_dim:2*n_dim]\n",
    "                adj_p[:] += aug_ans[:, 2*n_dim:2*n_dim + n_params]\n",
    "                adj_t[i_t-1] = aug_ans[:, 2*n_dim + n_params:]\n",
    "\n",
    "                del aug_z, aug_ans\n",
    "\n",
    "            ## Adjust 0 time adjoint with direct gradients\n",
    "            # Compute direct gradients \n",
    "            dLdz_0 = dLdz[0]\n",
    "            dLdt_0 = torch.bmm(torch.transpose(dLdz_0.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0]\n",
    "\n",
    "            # Adjust adjoints\n",
    "            adj_z += dLdz_0\n",
    "            adj_t[0] = adj_t[0] - dLdt_0\n",
    "        return adj_z.view(bs, *z_shape), adj_t, adj_p, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode_solve(z0, t0, t1, f):\n",
    "    \"\"\"\n",
    "    Simplest Euler ODE initial value solver\n",
    "    \"\"\"\n",
    "    h_max = 0.05\n",
    "    n_steps = math.ceil((abs(t1 - t0)/h_max).max().item())\n",
    "\n",
    "    h = (t1 - t0)/n_steps\n",
    "    t = t0\n",
    "    z = z0\n",
    "\n",
    "    for i_step in range(n_steps):\n",
    "        z = z + h * f(z, t)\n",
    "        t = t + h\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "func = ConvODEF(64)\n",
    "ode = NeuralODE(func)\n",
    "model = Net(ode)\n",
    "\n",
    "model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainset, validset = torch.utils.data.random_split(trainset, [40000, 10000])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 10000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader.dataset), len(validloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b353fbe6cc424c89f0fe4f3ba974d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484abf002c21432ba759348bd1270214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1.4376111525058746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3296b091a34d6f951c481644a8d238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1.047448112821579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14de94fe74004a2cb81e4869aeadac9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.8763681351661682\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11302ab8fa394a3895a7d08798f4b9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.7632964090824127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2507a39a11240ccac1e944139bb902d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.6692695160865784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5d5997401441e2a33e5f860ce83ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.5979026133656502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6808541a974b45ac02ea9289420b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.5452237495064736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74bb4b08278141568b8cc1c43263fe64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.49450257897377015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7750f866dd4beb8f514fdc1e08b180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.44702655816078185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05059c7f11d4ff9845b9e5018cde404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.4091317754507065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f066bfecd5470f89d62c218ec4a312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.37195222423672675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08feadb5d3346a690f119f4d60d700f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.3423196662724018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843118e9f31740e8b811933152739409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.3106403835892677\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3e9e375d4b40c98ffadc04973cc2fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.2837643409371376\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df41ac7eacc4604a18daf156c44d67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.2589199010133743\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8b43be3aac4298a85f1c2f2dd0efc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.2346579485297203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8741e2e26c5c4cc695a837ca2590b1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.21686306531429292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff063482b8a4f2fba30fdbb725c1c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.1981902094900608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8cae3a0fd54df09019bd1d60aad481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.1841968933880329\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cd74eddfcb4df793d446dab7c70585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.1760120445072651\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "size = len(trainloader.dataset) / trainloader.batch_size\n",
    "\n",
    "for epoch in tnrange(epochs, desc='Epoch'):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in tqdm_notebook(trainloader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(\"Loss {}\".format(running_loss / size))\n",
    "    torch.save(model.state_dict(), \"model_epoch{}.pt\".format(epoch))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Net(ode)\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(\"model_epoch{}.pt\".format(0)))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 50000 train images: 95 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 50000 train images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy of the network on the 10000 validation images: 60.66\n",
      "Epoch: 1 Accuracy of the network on the 10000 validation images: 66.67\n",
      "Epoch: 2 Accuracy of the network on the 10000 validation images: 70.31\n",
      "Epoch: 3 Accuracy of the network on the 10000 validation images: 74.45\n",
      "Epoch: 4 Accuracy of the network on the 10000 validation images: 75.62\n",
      "Epoch: 5 Accuracy of the network on the 10000 validation images: 75.56\n",
      "Epoch: 6 Accuracy of the network on the 10000 validation images: 76.59\n",
      "Epoch: 7 Accuracy of the network on the 10000 validation images: 76.78\n",
      "Epoch: 8 Accuracy of the network on the 10000 validation images: 77.54\n",
      "Epoch: 9 Accuracy of the network on the 10000 validation images: 78.22\n",
      "Epoch: 10 Accuracy of the network on the 10000 validation images: 78.08\n",
      "Epoch: 11 Accuracy of the network on the 10000 validation images: 79.19\n",
      "Epoch: 12 Accuracy of the network on the 10000 validation images: 76.91\n",
      "Epoch: 13 Accuracy of the network on the 10000 validation images: 78.88\n",
      "Epoch: 14 Accuracy of the network on the 10000 validation images: 76.68\n",
      "Epoch: 15 Accuracy of the network on the 10000 validation images: 78.58\n",
      "Epoch: 16 Accuracy of the network on the 10000 validation images: 78.47\n",
      "Epoch: 17 Accuracy of the network on the 10000 validation images: 78.45\n",
      "Epoch: 18 Accuracy of the network on the 10000 validation images: 77.13\n",
      "Epoch: 19 Accuracy of the network on the 10000 validation images: 78.4\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    model = Net(ode)\n",
    "    model = model.cuda()\n",
    "    model.load_state_dict(torch.load(\"model_epoch{}.pt\".format(i)))\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Epoch: {} Accuracy of the network on the 10000 validation images: {}%'.format(i,100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 78 %\n"
     ]
    }
   ],
   "source": [
    "model = Net(ode)\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(\"model_epoch{}.pt\".format(11)))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 85 %\n",
      "Accuracy of   car : 86 %\n",
      "Accuracy of  bird : 70 %\n",
      "Accuracy of   cat : 59 %\n",
      "Accuracy of  deer : 75 %\n",
      "Accuracy of   dog : 58 %\n",
      "Accuracy of  frog : 85 %\n",
      "Accuracy of horse : 85 %\n",
      "Accuracy of  ship : 89 %\n",
      "Accuracy of truck : 83 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
